{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11-3.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "wk4S9-VljwR6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "313b7ed9-01a4-401b-fca1-1d579c139e12"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "tf.set_random_seed(777)  \n",
        "\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "class Model:\n",
        "\n",
        "    def __init__(self, sess, name):\n",
        "        self.sess = sess\n",
        "        self.name = name\n",
        "        self._build_net()\n",
        "\n",
        "    def _build_net(self):\n",
        "        with tf.variable_scope(self.name):\n",
        "            self.keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "            \n",
        "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
        "            \n",
        "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
        "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "            W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
        "            \n",
        "            L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
        "            L1 = tf.nn.relu(L1)\n",
        "            L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
        "                                strides=[1, 2, 2, 1], padding='SAME')\n",
        "            L1 = tf.nn.dropout(L1, keep_prob=self.keep_prob)\n",
        "            W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
        "          \n",
        "            L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
        "            L2 = tf.nn.relu(L2)\n",
        "            L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
        "                                strides=[1, 2, 2, 1], padding='SAME')\n",
        "            L2 = tf.nn.dropout(L2, keep_prob=self.keep_prob)\n",
        "            W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
        "            L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
        "            L3 = tf.nn.relu(L3)\n",
        "            L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
        "                                1, 2, 2, 1], padding='SAME')\n",
        "            L3 = tf.nn.dropout(L3, keep_prob=self.keep_prob)\n",
        "\n",
        "            L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
        "            W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
        "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
        "            b4 = tf.Variable(tf.random_normal([625]))\n",
        "            L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
        "            L4 = tf.nn.dropout(L4, keep_prob=self.keep_prob)\n",
        "    \n",
        "            W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
        "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
        "            b5 = tf.Variable(tf.random_normal([10]))\n",
        "            self.logits = tf.matmul(L4, W5) + b5\n",
        "       \n",
        "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "            logits=self.logits, labels=self.Y))\n",
        "        self.optimizer = tf.train.AdamOptimizer(\n",
        "            learning_rate=learning_rate).minimize(self.cost)\n",
        "\n",
        "        correct_prediction = tf.equal(\n",
        "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    def predict(self, x_test, keep_prop=1.0):\n",
        "        return self.sess.run(self.logits, feed_dict={self.X: x_test, self.keep_prob: keep_prop})\n",
        "\n",
        "    def get_accuracy(self, x_test, y_test, keep_prop=1.0):\n",
        "        return self.sess.run(self.accuracy, feed_dict={self.X: x_test, self.Y: y_test, self.keep_prob: keep_prop})\n",
        "\n",
        "    def train(self, x_data, y_data, keep_prop=0.7):\n",
        "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
        "            self.X: x_data, self.Y: y_data, self.keep_prob: keep_prop})\n",
        "\n",
        "sess = tf.Session()\n",
        "m1 = Model(sess, \"m1\")\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "print('Learning Started!')\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        c, _ = m1.train(batch_xs, batch_ys)\n",
        "        avg_cost += c / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Learning Finished!')\n",
        "\n",
        "print('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-67d454141def>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From <ipython-input-1-67d454141def>:111: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "Learning Started!\n",
            "Epoch: 0001 cost = 0.370543289\n",
            "Epoch: 0002 cost = 0.100450296\n",
            "Epoch: 0003 cost = 0.073585106\n",
            "Epoch: 0004 cost = 0.061380149\n",
            "Epoch: 0005 cost = 0.054990616\n",
            "Epoch: 0006 cost = 0.046912566\n",
            "Epoch: 0007 cost = 0.043239948\n",
            "Epoch: 0008 cost = 0.039860626\n",
            "Epoch: 0009 cost = 0.037047697\n",
            "Epoch: 0010 cost = 0.035550021\n",
            "Epoch: 0011 cost = 0.031770481\n",
            "Epoch: 0012 cost = 0.030194471\n",
            "Epoch: 0013 cost = 0.028639981\n",
            "Epoch: 0014 cost = 0.028132488\n",
            "Epoch: 0015 cost = 0.026405574\n",
            "Learning Finished!\n",
            "Accuracy: 0.9938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2kYsNNDElB5C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "d304e659-8cdc-4a1c-cd36-4179a1eda0b8"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "tf.set_random_seed(777)  \n",
        "\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "class Model:\n",
        "\n",
        "    def __init__(self, sess, name):\n",
        "        self.sess = sess\n",
        "        self.name = name\n",
        "        self._build_net()\n",
        "\n",
        "    def _build_net(self):\n",
        "        with tf.variable_scope(self.name):\n",
        "            self.training = tf.placeholder(tf.bool)\n",
        "\n",
        "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
        "\n",
        "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
        "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "            conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3],\n",
        "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
        "    \n",
        "            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
        "                                            padding=\"SAME\", strides=2)\n",
        "            dropout1 = tf.layers.dropout(inputs=pool1,\n",
        "                                         rate=0.3, training=self.training)\n",
        "\n",
        "            conv2 = tf.layers.conv2d(inputs=dropout1, filters=64, kernel_size=[3, 3],\n",
        "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
        "            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
        "                                            padding=\"SAME\", strides=2)\n",
        "            dropout2 = tf.layers.dropout(inputs=pool2,\n",
        "                                         rate=0.3, training=self.training)\n",
        "\n",
        "            conv3 = tf.layers.conv2d(inputs=dropout2, filters=128, kernel_size=[3, 3],\n",
        "                                     padding=\"same\", activation=tf.nn.relu)\n",
        "            pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
        "                                            padding=\"same\", strides=2)\n",
        "            dropout3 = tf.layers.dropout(inputs=pool3,\n",
        "                                         rate=0.3, training=self.training)\n",
        "\n",
        "            flat = tf.reshape(dropout3, [-1, 128 * 4 * 4])\n",
        "            dense4 = tf.layers.dense(inputs=flat,\n",
        "                                     units=625, activation=tf.nn.relu)\n",
        "            dropout4 = tf.layers.dropout(inputs=dense4,\n",
        "                                         rate=0.5, training=self.training)\n",
        "\n",
        "            self.logits = tf.layers.dense(inputs=dropout4, units=10)\n",
        "\n",
        "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "            logits=self.logits, labels=self.Y))\n",
        "        self.optimizer = tf.train.AdamOptimizer(\n",
        "            learning_rate=learning_rate).minimize(self.cost)\n",
        "\n",
        "        correct_prediction = tf.equal(\n",
        "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    def predict(self, x_test, training=False):\n",
        "        return self.sess.run(self.logits,\n",
        "                             feed_dict={self.X: x_test, self.training: training})\n",
        "\n",
        "    def get_accuracy(self, x_test, y_test, training=False):\n",
        "        return self.sess.run(self.accuracy,\n",
        "                             feed_dict={self.X: x_test,\n",
        "                                        self.Y: y_test, self.training: training})\n",
        "\n",
        "    def train(self, x_data, y_data, training=True):\n",
        "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
        "            self.X: x_data, self.Y: y_data, self.training: training})\n",
        "\n",
        "sess = tf.Session()\n",
        "m1 = Model(sess, \"m1\")\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "print('Learning Started!')\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        c, _ = m1.train(batch_xs, batch_ys)\n",
        "        avg_cost += c / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Learning Finished!')\n",
        "\n",
        "print('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-0d5f51e72e4d>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From <ipython-input-1-0d5f51e72e4d>:75: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "Learning Started!\n",
            "Epoch: 0001 cost = 0.286824545\n",
            "Epoch: 0002 cost = 0.089124623\n",
            "Epoch: 0003 cost = 0.068958454\n",
            "Epoch: 0004 cost = 0.055018626\n",
            "Epoch: 0005 cost = 0.047836716\n",
            "Epoch: 0006 cost = 0.044725034\n",
            "Epoch: 0007 cost = 0.041139857\n",
            "Epoch: 0008 cost = 0.037811795\n",
            "Epoch: 0009 cost = 0.035534235\n",
            "Epoch: 0010 cost = 0.033176923\n",
            "Epoch: 0011 cost = 0.031450082\n",
            "Epoch: 0012 cost = 0.030705730\n",
            "Epoch: 0013 cost = 0.028742628\n",
            "Epoch: 0014 cost = 0.027086368\n",
            "Epoch: 0015 cost = 0.026980745\n",
            "Learning Finished!\n",
            "Accuracy: 0.9945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s2CPJC-_l5NZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1448
        },
        "outputId": "fa5fdd2c-5e29-46c6-bb5d-d9372c01622a"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "tf.set_random_seed(777)  \n",
        "\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_epochs = 20\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "class Model:\n",
        "\n",
        "    def __init__(self, sess, name):\n",
        "        self.sess = sess\n",
        "        self.name = name\n",
        "        self._build_net()\n",
        "\n",
        "    def _build_net(self):\n",
        "        with tf.variable_scope(self.name):\n",
        "            \n",
        "            self.training = tf.placeholder(tf.bool)\n",
        "            \n",
        "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
        "\n",
        "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
        "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "            conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3],\n",
        "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
        "            \n",
        "            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
        "                                            padding=\"SAME\", strides=2)\n",
        "            dropout1 = tf.layers.dropout(inputs=pool1,\n",
        "                                         rate=0.3, training=self.training)\n",
        "\n",
        "            \n",
        "            conv2 = tf.layers.conv2d(inputs=dropout1, filters=64, kernel_size=[3, 3],\n",
        "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
        "            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
        "                                            padding=\"SAME\", strides=2)\n",
        "            dropout2 = tf.layers.dropout(inputs=pool2,\n",
        "                                         rate=0.3, training=self.training)\n",
        "\n",
        "            conv3 = tf.layers.conv2d(inputs=dropout2, filters=128, kernel_size=[3, 3],\n",
        "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
        "            pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
        "                                            padding=\"SAME\", strides=2)\n",
        "            dropout3 = tf.layers.dropout(inputs=pool3,\n",
        "                                         rate=0.3, training=self.training)\n",
        "\n",
        "            flat = tf.reshape(dropout3, [-1, 128 * 4 * 4])\n",
        "            dense4 = tf.layers.dense(inputs=flat,\n",
        "                                     units=625, activation=tf.nn.relu)\n",
        "            dropout4 = tf.layers.dropout(inputs=dense4,\n",
        "                                         rate=0.5, training=self.training)\n",
        "\n",
        "            self.logits = tf.layers.dense(inputs=dropout4, units=10)\n",
        "\n",
        "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "            logits=self.logits, labels=self.Y))\n",
        "        self.optimizer = tf.train.AdamOptimizer(\n",
        "            learning_rate=learning_rate).minimize(self.cost)\n",
        "\n",
        "        correct_prediction = tf.equal(\n",
        "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    def predict(self, x_test, training=False):\n",
        "        return self.sess.run(self.logits,\n",
        "                             feed_dict={self.X: x_test, self.training: training})\n",
        "\n",
        "    def get_accuracy(self, x_test, y_test, training=False):\n",
        "        return self.sess.run(self.accuracy,\n",
        "                             feed_dict={self.X: x_test,\n",
        "                                        self.Y: y_test, self.training: training})\n",
        "\n",
        "    def train(self, x_data, y_data, training=True):\n",
        "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
        "            self.X: x_data, self.Y: y_data, self.training: training})\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "models = []\n",
        "num_models = 10\n",
        "for m in range(num_models):\n",
        "    models.append(Model(sess, \"model\" + str(m)))\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "print('Learning Started!')\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost_list = np.zeros(len(models))\n",
        "    total_batch = int(mnist.train.num_examples / batch_size)\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "\n",
        "        for m_idx, m in enumerate(models):\n",
        "            c, _ = m.train(batch_xs, batch_ys)\n",
        "            avg_cost_list[m_idx] += c / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', avg_cost_list)\n",
        "\n",
        "print('Learning Finished!')\n",
        "\n",
        "test_size = len(mnist.test.labels)\n",
        "predictions = np.zeros([test_size, 10])\n",
        "for m_idx, m in enumerate(models):\n",
        "    print(m_idx, 'Accuracy:', m.get_accuracy(\n",
        "        mnist.test.images, mnist.test.labels))\n",
        "    p = m.predict(mnist.test.images)\n",
        "    predictions += p\n",
        "\n",
        "ensemble_correct_prediction = tf.equal(\n",
        "    tf.argmax(predictions, 1), tf.argmax(mnist.test.labels, 1))\n",
        "ensemble_accuracy = tf.reduce_mean(\n",
        "    tf.cast(ensemble_correct_prediction, tf.float32))\n",
        "print('Ensemble accuracy:', sess.run(ensemble_accuracy))\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-7121abb3de9a>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From <ipython-input-1-7121abb3de9a>:65: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "Learning Started!\n",
            "Epoch: 0001 cost = [0.28800284 0.29811795 0.27843346 0.28993729 0.27951768 0.28859859\n",
            " 0.27864006 0.2897492  0.28173587 0.27471184]\n",
            "Epoch: 0002 cost = [0.08843375 0.09087959 0.08930874 0.09045461 0.08740588 0.08930901\n",
            " 0.0876394  0.08918782 0.08962514 0.08826555]\n",
            "Epoch: 0003 cost = [0.06946033 0.06849763 0.06934375 0.0672613  0.0670211  0.06917384\n",
            " 0.06667972 0.06838407 0.06601981 0.06705802]\n",
            "Epoch: 0004 cost = [0.05552425 0.0571208  0.05807169 0.05696524 0.05569184 0.05515213\n",
            " 0.0552     0.05705123 0.057888   0.05618126]\n",
            "Epoch: 0005 cost = [0.04796827 0.0510824  0.04946423 0.05023014 0.04825176 0.0497155\n",
            " 0.04984127 0.04953848 0.04915243 0.04991329]\n",
            "Epoch: 0006 cost = [0.04428881 0.04571826 0.04254294 0.04466798 0.0437638  0.04527931\n",
            " 0.04484335 0.04418199 0.04685599 0.04489616]\n",
            "Epoch: 0007 cost = [0.04141219 0.0413266  0.04015555 0.04012583 0.04268694 0.04193646\n",
            " 0.04238694 0.04135298 0.04078813 0.04146837]\n",
            "Epoch: 0008 cost = [0.03674393 0.03911312 0.03684474 0.03999022 0.03743763 0.03824158\n",
            " 0.03706617 0.03815985 0.03754674 0.04007369]\n",
            "Epoch: 0009 cost = [0.03621781 0.03613504 0.03428491 0.03557654 0.03398843 0.03537405\n",
            " 0.03374576 0.03631532 0.03544955 0.0352571 ]\n",
            "Epoch: 0010 cost = [0.03268179 0.03508602 0.03342903 0.03418268 0.03484026 0.03503056\n",
            " 0.03322739 0.03424471 0.03195243 0.03528546]\n",
            "Epoch: 0011 cost = [0.03257583 0.0316161  0.03214508 0.031878   0.033091   0.03245764\n",
            " 0.03171459 0.0295389  0.03198389 0.03190676]\n",
            "Epoch: 0012 cost = [0.02966135 0.03151518 0.03013619 0.03084678 0.03101044 0.03197135\n",
            " 0.02909465 0.0319049  0.03131659 0.03055558]\n",
            "Epoch: 0013 cost = [0.02740483 0.02871776 0.02959471 0.02985494 0.02834181 0.03137046\n",
            " 0.02953667 0.02837777 0.02735014 0.0286065 ]\n",
            "Epoch: 0014 cost = [0.02776731 0.02842603 0.02904305 0.02886221 0.02802111 0.02902731\n",
            " 0.02792594 0.02621377 0.02738181 0.02540332]\n",
            "Epoch: 0015 cost = [0.02578541 0.02526142 0.0268756  0.02751608 0.02597053 0.02668849\n",
            " 0.02598156 0.0268933  0.02768508 0.02758541]\n",
            "Epoch: 0016 cost = [0.02552005 0.02359036 0.02534967 0.02799085 0.02583521 0.0264642\n",
            " 0.02579674 0.02632463 0.02496491 0.0259758 ]\n",
            "Epoch: 0017 cost = [0.02489321 0.02470102 0.02344835 0.02438015 0.02280212 0.02388317\n",
            " 0.0259166  0.02547825 0.02562746 0.02510767]\n",
            "Epoch: 0018 cost = [0.02312129 0.02389599 0.02547189 0.02650834 0.02573558 0.02583209\n",
            " 0.02451511 0.02339346 0.0244135  0.0239663 ]\n",
            "Epoch: 0019 cost = [0.0241356  0.02517456 0.02292137 0.02445405 0.02317395 0.02423242\n",
            " 0.02408331 0.02427867 0.02401948 0.02307546]\n",
            "Epoch: 0020 cost = [0.02235716 0.02454986 0.02225463 0.02389153 0.02238515 0.02289834\n",
            " 0.02191806 0.02284021 0.02449    0.0217956 ]\n",
            "Learning Finished!\n",
            "0 Accuracy: 0.9939\n",
            "1 Accuracy: 0.9934\n",
            "2 Accuracy: 0.9952\n",
            "3 Accuracy: 0.9938\n",
            "4 Accuracy: 0.9936\n",
            "5 Accuracy: 0.9924\n",
            "6 Accuracy: 0.994\n",
            "7 Accuracy: 0.9943\n",
            "8 Accuracy: 0.9942\n",
            "9 Accuracy: 0.9943\n",
            "Ensemble accuracy: 0.9955\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}